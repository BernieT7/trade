{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "muVNyMIdhZj4"
      },
      "outputs": [],
      "source": [
        "!pip install openai\n",
        "!pip install python-dotenv\n",
        "!pip install gradio==3.48.0\n",
        "!pip install pytubefix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "from dotenv import dotenv_values\n",
        "config = dotenv_values('.env')\n",
        "client = OpenAI(api_key=config[\"API_KEY\"])"
      ],
      "metadata": {
        "id": "SOQmX3DmoBrC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pytubefix import YouTube, Playlist"
      ],
      "metadata": {
        "id": "MyLC9dUvqnCt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_audio_text(audio_path, title):\n",
        "  audio = open(audio_path, \"rb\")               # 讀取音檔\n",
        "  res = client.audio.transcriptions.create(          # 利用audioAPI將音檔轉換為文字\n",
        "      model=\"whisper-1\",\n",
        "      file=audio,\n",
        "      prompt=title                      # 以影片標題引導模型的指示\n",
        "  )\n",
        "  return res.text                        # 回傳影片音檔文字"
      ],
      "metadata": {
        "id": "XuoMl-d-mtDl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_video_title_text(video_url, audio_name):\n",
        "  video = YouTube(video_url)                  # 創建YT影片\n",
        "  stream = video.streams.filter(only_audio=True).first()    # 取得YT影片音檔\n",
        "  audio_path = stream.download(filename=audio_name)       # 將音檔下載至本地端\n",
        "  text = get_audio_text(audio_path, video.title)        # 取得文字\n",
        "  return video.title, text                   # 回傳影片標題及文字"
      ],
      "metadata": {
        "id": "2EwBadEonptE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_playlist_info(playlist_url):\n",
        "  playlist = Playlist(playlist_url)                  # 取得playlist裡所有影片的網址\n",
        "  videos_info = {}\n",
        "  for idx, video_url in enumerate(playlist):\n",
        "    title, text = get_video_title_text(video_url, f\"{idx}.mp3\")  # 取得所有影片標題及文字\n",
        "    videos_info[title] = text                    # 存放所有影片標題及文字\n",
        "  return videos_info                          # 回傳所有影片標題及文字"
      ],
      "metadata": {
        "id": "bIRXOX-Lp95g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "playlist_url = \"https://www.youtube.com/playlist?list=PLrZrfGLGySzcZoVhb4idy5B0XI25ZhnF7\" # 引用YouTuber柴鼠兄弟的playList\n",
        "playlist_info = get_playlist_info(playlist_url)"
      ],
      "metadata": {
        "id": "EpTzjv8RtJMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "f8OQZ2quNv5J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(list(playlist_info.items()), columns=[\"title\", \"text\"])\n",
        "df.to_csv(\"video_text.csv\", index=False)\n",
        "df = pd.read_csv(\"video_text.csv\")"
      ],
      "metadata": {
        "id": "ahXREBFyta0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_text(all_text, title):                # 由於模型能容納的token數有限，原本一段影片的總token數遠超模型限制，所以要將每句話分割出來，分次embedding轉換\n",
        "  text_list = all_text.split(' ')              # 把每句話分開\n",
        "  text = title                        # 分開後前面加上title也就是後面引導模型的指示\n",
        "  new_text_list = []                     # 接收加上title後的新text_list\n",
        "  for idx, i in enumerate(text_list):            # 利用for loop昨上述任務\n",
        "    text += f\",{i}\"\n",
        "    if (idx+1)%50==0 or idx==len(text_list)-1:       # 每50句話一組或是做到最後一組就將結果存入new_text_list\n",
        "      new_text_list.append(text)\n",
        "      text = title\n",
        "  return new_text_list"
      ],
      "metadata": {
        "id": "DY98JE3xuCqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_text_list = []\n",
        "for idx, text in enumerate(df[\"text\"].values):        # 把playlist的所有影片分割\n",
        "  split_text_list += split_text(text, df[\"title\"][idx])\n",
        "\n",
        "df = pd.DataFrame(split_text_list, columns=['split_text_list'])"
      ],
      "metadata": {
        "id": "WmlEKn8vKbmf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_embedding(text):\n",
        "  res = client.embeddings.create(            # 利用模型將文字向量化\n",
        "      model=\"text-embedding-ada-002\",\n",
        "      input=text                    # 輸入欲轉換文字\n",
        "  )\n",
        "  return res.data[0].embedding              # 回傳轉換結果"
      ],
      "metadata": {
        "id": "7hF68vNbN0Op"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_text_embeddings = [get_embedding(i) for i in df[\"split_text_list\"]]   # 將每段文字轉換成向量\n",
        "df[\"embeddings\"] = split_text_embeddings          # 創建新的column，將向量化後的結果展現出來"
      ],
      "metadata": {
        "id": "-2P2_k_hODIa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "from scipy import spatial\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "def distances_from_embeddings(\n",
        "    query_embedding: List[float],\n",
        "    embeddings: List[List[float]],\n",
        "    distance_metric=\"cosine\",\n",
        ") -> List[List]:\n",
        "    \"\"\"Return the distances between a query embedding and a list of embeddings.\"\"\"\n",
        "    distance_metrics = {\n",
        "        \"cosine\": spatial.distance.cosine,\n",
        "        \"L1\": spatial.distance.cityblock,\n",
        "        \"L2\": spatial.distance.euclidean,\n",
        "        \"Linf\": spatial.distance.chebyshev,\n",
        "    }\n",
        "    distances = [\n",
        "        distance_metrics[distance_metric](query_embedding, embedding)\n",
        "        for embedding in embeddings\n",
        "    ]\n",
        "    return distances\n",
        "\n",
        "\n",
        "def indices_of_nearest_neighbors_from_distances(distances) -> np.ndarray:\n",
        "    \"\"\"Return a list of indices of nearest neighbors from a list of distances.\"\"\"\n",
        "    return np.argsort(distances)"
      ],
      "metadata": {
        "id": "bxjTng8dQ1I9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def finance(question):\n",
        "  question_embeddings = get_embedding(question)\n",
        "  dist = distances_from_embeddings(question_embeddings, df[\"embeddings\"])\n",
        "  nearest_idx = indices_of_nearest_neighbors_from_distances(dist)\n",
        "  nearest_text = \"\"\n",
        "  for i in range(2):\n",
        "    nearest_text += df[\"split_text_list\"][nearest_idx[i]] + '\\n'\n",
        "\n",
        "  prompt = f\"\"\"\n",
        "  你是我的投資理財顧問，請根據以下內容回答此問題:{question}\n",
        "  如果沒有100%確定，就回答'我不知道'\n",
        "\n",
        "  ###\n",
        "  內容:\n",
        "  {nearest_text}\n",
        "  ###\n",
        "\n",
        "  \"\"\"\n",
        "  res = client.completions.create(\n",
        "      model=\"gpt-3.5-turbo-instruct\",\n",
        "      prompt=prompt,\n",
        "      max_tokens=500,\n",
        "      temperature=0\n",
        "  )\n",
        "  return res.choices[0].text"
      ],
      "metadata": {
        "id": "0PtEFug1QpZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=finance,\n",
        "    inputs=\"text\",\n",
        "    outputs=\"text\",\n",
        "    title=\"投資理財顧問\",\n",
        "    description=\"輸入您的問題:\",\n",
        "    allow_flagging=\"never\"\n",
        ")\n",
        "\n",
        "demo.launch(debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 715
        },
        "id": "Kjy7KTfdU7dD",
        "outputId": "bf25218e-6496-404b-d25f-0b33c280a797"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "IMPORTANT: You are using gradio version 3.48.0, however version 4.29.0 is available, please upgrade.\n",
            "--------\n",
            "Running on public URL: https://9d3dd1fca12ef97ccd.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://9d3dd1fca12ef97ccd.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://9d3dd1fca12ef97ccd.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    }
  ]
}